# 深度分页优化

最近做了一个项目中用到了分页，联表查询，模糊查询，一开始数据量少数代码的性能问题也不会体现出来，但是当数据量大时，出现了各种各样的问题

查询时间太长非常影响用户体验，所以对这些问题进行了优化。

## SQL语句的优化

每页10条，当我们查询第一页的时候，速度很快：

```mysql
SELECT * from plan where executor_id > 100 LIMIT 1,10;
```

![image-20230811182230112](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\1.png)

当我们翻到第1000000页的时候，查询效率急剧下降：

```mysql
SELECT * from plan where executor_id > 100 LIMIT 1000000,10;
```

![image-20230811182031856](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\2.png)

我们先来看下这个SQL的执行流程：

1. 通过**普通二级索引树**idx_executor_id，过滤executor_id条件，找到满足条件的记录ID。

   ![image-20230811182547086](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\3.png)

   

2. 通过ID，回到**主键索引树**，找到满足记录的行，然后取出展示的列（**回表**）

3. 扫描满足条件的1000010行，然后扔掉前1000000行，返回。

   ![4](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\4.png)

**SQL变慢原因有两个**：

1. limit语句会先扫描offset+n行，然后再丢弃掉前offset行，返回后n行数据。也就是说`limit 100000,10`，就会扫描100010行，而`limit 0,10`，只扫描10行。
2. `limit 1000000,10` 扫描更多的行数，也意味着**回表**更多的次数。

### **通过子查询优化**

因为以上的SQL，回表了1000010次，实际上，我们只需要10条数据，也就是我们只需要10次回表其实就够了。因此，我们可以通过**减少回表次数**来优化。

### **回顾B+ 树结构**

那么，如何减少回表次数呢？InnoDB中，索引分主键索引（聚簇索引）和二级索引

- 主键索引，叶子节点存放的是整行数据
- 二级索引，叶子节点存放的是**主键的值**。

如果我们把查询条件，转移回到主键索引树，那就可以减少回表次数

因为二级索引叶子节点是有主键ID的，所以我们直接根据`idx_executor_id`来查主键ID即可，同时我们把 `limit 1000000`的条件，也转移到子查询

完整SQL如下：

```mysql
SELECT * from plan WHERE id in (SELECT id from (SELECT id from plan where executor_id > 100 LIMIT 1000000,10)as a);
```



![image-20230811190135713](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\7.png)

我们来看下执行计划

![image-20230811190405343](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\8.png)

由执行计划得知，子查询 table a查询是用到了`idx_executor_id`索引。在索引上拿到了聚集索引的主键ID,省去了回表操作

![7](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\9.png)

但我再实验中碰到了很奇怪的情况，子查询比直接查要慢，且子查询内部没有问题（不知道为什么无法复现了），去网上查找说是MySQL查询优化器直接把IN子句转换成了EXISTS的相关子查询，说是改成exist或join会更好一点

```mysql
SELECT p.* from plan p INNER JOIN (SELECT id from plan where executor_id > 100 LIMIT 1000000,10) a on a.id = p.id;
```



![image-20230812115341093](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\10.png)

![image-20230812115736640](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\11.png)

就是用过这个join后我的in子查询就恢复了



EXIST

```mysql
SELECT * FROM plan WHERE exists (SELECT id FROM (SELECT id FROM plan WHERE executor_id> 100 LIMIT 1000000,10) AS b WHERE b.id = plan.id);
```



![image-20230812120012793](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\12.png)

![image-20230812120039719](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\13.png)

我们用EXPLAIN和SHOW WARNINGS来看一下MySQL查询优化器把他们优化成了什么样

IN

![image-20230812120338344](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\14.png)

JOIN

![image-20230812120417472](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\15.png)

EXIST

![image-20230812120535892](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\16.png)

可以看到再MySQL8.0版本查询优化器是把子查询优化成了join，也就是说其实IN和JOIN，EXIST是一样的

但是一般这种查询在service拆分做逻辑处理会更好一点



### **使用分页游标**

实现方式就是：当我们查询第二页的时候，把第一页的查询结果放到第二页的查询条件中。

例如：首先查询第一页

```mysql
SELECT * FROM plan WHERE executor_id > 100limit 10;
```

![image-20230812141200876](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\17.png)

然后查询第二页，把第一页的查询结果放到第二页查询条件中：

```
select * from plan where executor_id > 100 and id > 660 limit 10;
```

![image-20230812141226971](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\18.png)

这样相当于每次都是查询第一页，也就不存在深分页的问题了

这样的查询方式虽然好用，但是又带来一个问题，就是无法跳转到指定页数，只能一页页向下翻。

比如我现在是第一页要跳到第二页时，那么我就要把条件id+20

![image-20230812141702890](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\19.png)

而此时id为675的数据被删除了

那么id为676的数据重复出现在了第二页和第三页

![image-20230812141809611](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\20.png)

所以这种查询只适合特定场景，不追求数据的唯一性



## 联表查询优化

在实际开发中，我们不可避免的要关联几张数据表来合成最终的展示数据

![image-20230812150118820](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\21.png)

![image-20230812155034241](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\22.png)

我们可以用以下查询来代替：

![image-20230812150332586](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\23.png)

![image-20230812150522966](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\24.png)

通过两张表的关联字段来进行拆分，先查出一张表所需要的字段和另一张表关联的字段

再通过关联的字段去另一张表查，可以再service层做逻辑处理

![image-20230812150749852](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\25.png)

![image-20230812160152261](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\26.png)

可以看到联表查询会慢很多

为什么会这样？

INNER JOIN：查询两个表之间的交集

取值时遵循笛卡尔乘积，即利用双层循环遍历两个表的数据，若table1的结果集比较少，那么就拿它当作外层循环，称为驱动表，外层循环每取一条数据，就拿该数据去内层循环table2表中匹配结果集，此时table2称为被驱动表，如果表记录比较少的话，效率还是OK的，有时效率超过单表查询。但是如果数据量上去，多表查询是笛卡尔乘积方式，需要检索的数据是几何倍上升的。另外多表查询索引设计上也考验开发者的功底，索引设计不合理，大数据量下的多表查询，很可能把数据库拖垮。

相比而言，拆分成单表查询+代码上组装，业务逻辑更清晰，优化更方便，单个表的索引设计上也更简单。



## 倒排索引优化模糊查询

在生活中我们经常会遇到使用模糊查询的场景

而模糊查询因为走不了索引会进行全表扫描而效率低下，这时我们可以使用倒排索引来进行模糊查询的优化

首先对原始文档数据进行编号，形成列表，就是一个文档列表

![v2-d50ffd4b3bc38e25e281fea9e07e14e6_720w](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\27.png)

创建倒排索引列表

然后对列表中数据进行分词，得到词条。对词条进行编号，以词条创建索引。然后记录下包含该词条的所有文档编号（及其它信息）。

![v2-0e77a230cbce4cd3c8b8e121bb211518_720w](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\28.png)

搜索的过程：

当用户输入任意的词条时，首先对用户输入的数据进行分词，得到用户要搜索的所有词条，然后拿着这些词条去倒排索引列表中进行匹配。找到这些词条就能找到包含这些词条的所有文档的编号。然后根据这些编号去文档列表中找到文档

#### java实现

我们现在pom文件中引入结巴分词器的依赖

![image-20230812162006612](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\29.png)

```xml
<dependency>
    <groupId>com.huaban</groupId>
    <artifactId>jieba-analysis</artifactId>
    <version>1.0.2</version>
</dependency>
```

下载dict词库包:

[huaban/jieba-analysis: 结巴分词(java版) (github.com)](https://github.com/huaban/jieba-analysis)

放入项目:

![image-20230812162453658](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\30.png)

测试代码:

```java
package com.datang.insert;

import java.nio.file.Paths;
import com.huaban.analysis.jieba.JiebaSegmenter;
import com.huaban.analysis.jieba.WordDictionary;

public class JiebaTest{

    private JiebaSegmenter segmenter = new JiebaSegmenter();
    String sentences = "鲁镇的酒店的格局是和别处不同的都是当街一个曲尺形的大柜台柜里面预备着热水可以随时温酒";

    /**
     * 读取conf目录下所有的自定义词库**.dict文件。
     */
    protected void setUp() throws Exception {
        WordDictionary.getInstance().init(Paths.get("conf"));
    }


    public void testCutForSearch() {
        System.out.println(segmenter.sentenceProcess(sentences));
    }

    public static void main(String[] args) {
        new JiebaTest().testCutForSearch();
    }
}
```

![image-20230812163248076](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\31.png)

我们把所需要的mission表中的每行id和name全都拿到

再把name进行分词分完词后将id和词放进map中

![image-20230812162845028](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\32.png)

![image-20230812163722188](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\33.png)

![image-20230812163911491](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\34.png)

我们拿一个id有接近5000条的分词来做对比

![image-20230812165454132](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\35.png)

![image-20230812165604914](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\36.png)

不使用倒排索引需要9秒

![image-20230812170934125](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\37.png)

而使用倒排索引只要172毫秒

![image-20230812171145051](C:\Users\19654\AppData\Roaming\Typora\typora-user-images\38.png)

当然这也是有代价的，倒排索引是放在内存中的，如此多的数据是非常占内存的
